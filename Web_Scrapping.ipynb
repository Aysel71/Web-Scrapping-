{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Web Scrapping\n"
      ],
      "metadata": {
        "id": "F_P_rV7elhdQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Urllib3** is a powerful HTTP client library for Python. This makes it easy to perform HTTP requests programmatically. It handles HTTP headers, retries, redirects, and other low-level details, making it an excellent library for web scraping. It also supports SSL verification, connection pooling, and proxying.\n",
        "\n",
        "**BeautifulSoup** allows you to parse HTML and XML documents. Using API, you can easily navigate through the HTML document tree and extract tags, meta titles, attributes, text, and other content. BeautifulSoup is also known for its robust error handling.\n",
        "\n",
        "**MechanicalSoup **automates the interaction between a web browser and a website efficiently. It provides a high-level API for web scraping that simulates human behavior. With MechanicalSoup, you can interact with HTML forms, click buttons, and interact with elements like a real user.\n",
        "\n",
        "**Requests** is a simple yet powerful Python library for making HTTP requests. It is designed to be easy to use and intuitive, with a clean and consistent API. With Requests, you can easily send GET and POST requests, and handle cookies, authentication, and other HTTP features. It is also widely used in web scraping due to its simplicity and ease of use.\n",
        "\n",
        "**Selenium** allows you to automate web browsers such as Chrome, Firefox, and Safari and simulate human interaction with websites. You can click buttons, fill out forms, scroll pages, and perform other actions. It is also used for testing web applications and automating repetitive tasks.\n",
        "\n",
        "**Panda**s allow storing and manipulating data in various formats, including CSV, Excel, JSON, and SQL databases. Using Pandas, you can easily clean, transform, and analyze data extracted from websites.\n"
      ],
      "metadata": {
        "id": "NS0_XSH6X1rX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install selenium"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "angy-1moH473",
        "outputId": "43f9d2a6-252c-4eef-fc15-3a9c69485be6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: selenium in /usr/local/lib/python3.10/dist-packages (4.19.0)\n",
            "Requirement already satisfied: urllib3[socks]<3,>=1.26 in /usr/local/lib/python3.10/dist-packages (from selenium) (2.0.7)\n",
            "Requirement already satisfied: trio~=0.17 in /usr/local/lib/python3.10/dist-packages (from selenium) (0.25.0)\n",
            "Requirement already satisfied: trio-websocket~=0.9 in /usr/local/lib/python3.10/dist-packages (from selenium) (0.11.1)\n",
            "Requirement already satisfied: certifi>=2021.10.8 in /usr/local/lib/python3.10/dist-packages (from selenium) (2024.2.2)\n",
            "Requirement already satisfied: typing_extensions>=4.9.0 in /usr/local/lib/python3.10/dist-packages (from selenium) (4.10.0)\n",
            "Requirement already satisfied: attrs>=23.2.0 in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (23.2.0)\n",
            "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (2.4.0)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (3.6)\n",
            "Requirement already satisfied: outcome in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (1.3.0.post0)\n",
            "Requirement already satisfied: sniffio>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (1.2.0)\n",
            "Requirement already satisfied: wsproto>=0.14 in /usr/local/lib/python3.10/dist-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
            "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
            "Requirement already satisfied: h11<1,>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a8HyJQFhldn_"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import requests\n",
        "import re\n",
        "from bs4 import BeautifulSoup\n",
        "from selenium import webdriver\n",
        "from selenium.webdriver.common.keys import Keys\n",
        "from selenium.webdriver.chrome.options import Options\n",
        "from urllib.request import urlopen\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Common Web Scrapping Methods\n",
        "\n",
        "*  Parse website data using string methods and regular expressions\n",
        "*  Parse website data using an HTML parser\n",
        "*  Interact with forms and other website components"
      ],
      "metadata": {
        "id": "jn5Voe_JG98d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#urllib"
      ],
      "metadata": {
        "id": "S_QwPv4URDLv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from urllib.request import urlopen\n",
        "import urllib.request"
      ],
      "metadata": {
        "id": "ft1Pw7dARAHA"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To extract the HTML from the page, first use the HTTPResponse object’s .read() method, which returns a sequence of bytes. Then use .decode() to decode the bytes to a string using UTF-8:"
      ],
      "metadata": {
        "id": "tXIHRpGJSCZ4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Specify the URL of the webpage\n",
        "url = \"https://www.kaggle.com/\"\n",
        "\n",
        "# Send a request to the webpage and get the response\n",
        "response = urllib.request.urlopen(url)\n",
        "\n",
        "# Read the HTML content as bytes\n",
        "html_bytes = response.read()\n",
        "\n",
        "# Decode the bytes to a string using UTF-8 encoding\n",
        "html_content = html_bytes.decode('utf-8')\n",
        "\n",
        "# Now you have the HTML content as a string\n",
        "print(html_content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bBGtwvIPR15l",
        "outputId": "a7124bf5-f87d-4492-eb3e-4f61fc655115"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r\n",
            "\r\n",
            "<!DOCTYPE html>\r\n",
            "<html lang=\"en\">\r\n",
            "\r\n",
            "<head>\r\n",
            "  <title>Kaggle: Your Machine Learning and Data Science Community</title>\r\n",
            "  <meta charset=\"utf-8\" />\r\n",
            "    <meta name=\"robots\" content=\"index, follow\" />\r\n",
            "  <meta name=\"description\" content=\"Kaggle is the world&#x2019;s largest data science community with powerful tools and resources to help you achieve your data science goals.\" />\r\n",
            "  <meta name=\"turbolinks-cache-control\" content=\"no-cache\" />\r\n",
            "    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0, maximum-scale=5.0, minimum-scale=1.0\">\r\n",
            "  <meta name=\"theme-color\" content=\"#008ABC\" />\r\n",
            "  <script nonce=\"FDBOrchT596&#x2B;PBjKY5dn8g==\" type=\"text/javascript\">\r\n",
            "    window[\"pageRequestStartTime\"] = 1712488695964;\r\n",
            "    window[\"pageRequestEndTime\"] = 1712488695970;\r\n",
            "    window[\"initialPageLoadStartTime\"] = new Date().getTime();\r\n",
            "  </script>\r\n",
            "  <script nonce=\"FDBOrchT596&#x2B;PBjKY5dn8g==\" id=\"gsi-client\" src=\"https://accounts.google.com/gsi/client\" async defer></script>\r\n",
            "  <script nonce=\"FDBOrchT596&#x2B;PBjKY5dn8g==\">window.KAGGLE_JUPYTERLAB_PATH = \"/static/assets/jupyterlab/jupyterlab-index-0497beb6ae1b7d43c42d.html\";</script>\r\n",
            "  <link rel=\"preconnect\" href=\"https://www.google-analytics.com\" crossorigin=\"anonymous\" /><link rel=\"preconnect\" href=\"https://stats.g.doubleclick.net\" /><link rel=\"preconnect\" href=\"https://storage.googleapis.com\" /><link rel=\"preconnect\" href=\"https://apis.google.com\" />\r\n",
            "  <link href=\"/static/images/favicon.ico\" rel=\"shortcut icon\" type=\"image/x-icon\" />\r\n",
            "  <link rel=\"manifest\" href=\"/static/json/manifest.json\" crossorigin=\"use-credentials\">\r\n",
            "\r\n",
            "\r\n",
            "  <link rel=\"preconnect\" href=\"https://fonts.gstatic.com\" crossorigin />\r\n",
            "\r\n",
            "  <link href=\"https://fonts.googleapis.com/css?family=Inter:400,400i,500,500i,600,600i,700,700i&display=swap\"\r\n",
            "    rel=\"preload\" as=\"style\" />\r\n",
            "  <link href=\"https://fonts.googleapis.com/css2?family=Google+Symbols:FILL@0..1&display=block\"\r\n",
            "    rel=\"preload\" as=\"style\" />\r\n",
            "  <link href=\"https://fonts.googleapis.com/css?family=Inter:400,400i,500,500i,600,600i,700,700i&display=swap\"\r\n",
            "    rel=\"stylesheet\" media=\"print\" id=\"async-google-font-1\" />\r\n",
            "  <link href=\"https://fonts.googleapis.com/css2?family=Google+Symbols:FILL@0..1&display=block\"\r\n",
            "    rel=\"stylesheet\" media=\"print\" id=\"async-google-font-2\" />\r\n",
            "  <script nonce=\"FDBOrchT596&#x2B;PBjKY5dn8g==\" type=\"text/javascript\">\r\n",
            "    const styleSheetIds = [\"async-google-font-1\", \"async-google-font-2\"];\r\n",
            "    styleSheetIds.forEach(function (id) {\r\n",
            "      document.getElementById(id).addEventListener(\"load\", function() {\r\n",
            "        this.media = \"all\";\r\n",
            "      });\r\n",
            "    });\r\n",
            "  </script>\r\n",
            "\r\n",
            "  <script nonce=\"FDBOrchT596&#x2B;PBjKY5dn8g==\" src=\"https://www.google.com/recaptcha/enterprise.js?render=6LcW02cpAAAAAJlaJemsQQEwAiTEYB4aR6FYE_rD&waf=session\" async defer></script>\r\n",
            "   <style>.grecaptcha-badge { visibility: hidden; }</style>\r\n",
            "\r\n",
            "    <link rel=\"stylesheet\" type=\"text/css\" href=\"/static/assets/vendor.css?v=dne\" />\r\n",
            "    <link rel=\"stylesheet\" type=\"text/css\" href=\"/static/assets/app.css?v=d42a14acad2e5a1bfac8\" />\r\n",
            "\r\n",
            "  \r\n",
            "    \r\n",
            " \r\n",
            "      <script nonce=\"FDBOrchT596&#x2B;PBjKY5dn8g==\">\r\n",
            "        try{(function(a,s,y,n,c,h,i,d,e){d=s.createElement(\"style\");\r\n",
            "        d.appendChild(s.createTextNode(\"\"));s.head.appendChild(d);d=d.sheet;\r\n",
            "        y=y.map(x => d.insertRule(x + \"{ opacity: 0 !important }\"));\r\n",
            "        h.start=1*new Date;h.end=i=function(){y.forEach(x => x<d.cssRules.length ? d.deleteRule(x) : {})};\r\n",
            "        (a[n]=a[n]||[]).hide=h;setTimeout(function(){i();h.end=null},c);h.timeout=c;\r\n",
            "        })(window,document,['.site-header-react__nav'],'dataLayer',2000,{'GTM-52LNT9S':true});}catch(ex){}\r\n",
            "    </script>\r\n",
            "    <script nonce=\"FDBOrchT596&#x2B;PBjKY5dn8g==\">\r\n",
            "        window.dataLayer = window.dataLayer || [];\r\n",
            "        function gtag() { dataLayer.push(arguments); }\r\n",
            "        gtag('js', new Date());\r\n",
            "        gtag('config', 'G-T7QHS60L4Q', {\r\n",
            "            'optimize_id': 'GTM-52LNT9S',\r\n",
            "            'displayFeaturesTask': null,\r\n",
            "            'send_page_view': false,\r\n",
            "            'content_group1': 'Home'\r\n",
            "        });\r\n",
            "    </script>\r\n",
            "    <script nonce=\"FDBOrchT596&#x2B;PBjKY5dn8g==\" async src=\"https://www.googletagmanager.com/gtag/js?id=G-T7QHS60L4Q\"></script>\r\n",
            "\r\n",
            "  \r\n",
            "    \r\n",
            "    <meta property=\"og:title\" content=\"Kaggle: Your Machine Learning and Data Science Community\" />\r\n",
            "    <meta property=\"og:description\" content=\"Kaggle is the world&#x2019;s largest data science community with powerful tools and resources to help you achieve your data science goals.\" />\r\n",
            "    <meta property=\"og:url\" content=\"https://www.kaggle.com/\" />\r\n",
            "    <meta property=\"og:type\" content=\"website\" />\r\n",
            "\r\n",
            "\r\n",
            "  <meta name=\"twitter:site\" content=\"@Kaggle\" /> \r\n",
            "  \r\n",
            "    \r\n",
            "\r\n",
            "  \r\n",
            "    \r\n",
            "\r\n",
            "  \r\n",
            "    \r\n",
            "\r\n",
            "\r\n",
            "    <script nonce=\"FDBOrchT596&#x2B;PBjKY5dn8g==\">window['useKaggleAnalytics'] = true;</script>\r\n",
            "\r\n",
            "  <script id=\"gapi-target\" nonce=\"FDBOrchT596&#x2B;PBjKY5dn8g==\" src=\"https://apis.google.com/js/api.js\" defer\r\n",
            "    async></script>\r\n",
            "  <script nonce=\"FDBOrchT596+PBjKY5dn8g==\" src=\"/static/assets/runtime.js?v=67a0b6ddda2db212e5bb\" data-turbolinks-track=\"reload\"></script>\r\n",
            "  <script nonce=\"FDBOrchT596+PBjKY5dn8g==\" src=\"/static/assets/vendor.js?v=2edca12929552d93c5db\" data-turbolinks-track=\"reload\"></script>\r\n",
            "  <script nonce=\"FDBOrchT596+PBjKY5dn8g==\" src=\"/static/assets/app.js?v=1d2f39c032909e684cde\" data-turbolinks-track=\"reload\"></script>\r\n",
            "    <script nonce=\"FDBOrchT596&#x2B;PBjKY5dn8g==\" type=\"text/javascript\">\r\n",
            "      window.kaggleStackdriverConfig = {\r\n",
            "        key: 'AIzaSyA4eNqUdRRskJsCZWVz-qL655Xa5JEMreE',\r\n",
            "        projectId: 'kaggle-161607',\r\n",
            "        service: 'web-fe',\r\n",
            "        version: 'ci',\r\n",
            "        userId: '0'\r\n",
            "      }\r\n",
            "    </script>\r\n",
            "</head>\r\n",
            "\r\n",
            "<body data-turbolinks=\"false\">\r\n",
            "  <main>\r\n",
            "    \r\n",
            "\r\n",
            "\r\n",
            "\r\n",
            "\r\n",
            "\r\n",
            "<div id=\"site-container\"></div>\r\n",
            "\r\n",
            "<div id=\"site-body\" class=\"hide\">\r\n",
            "    \r\n",
            "\r\n",
            "</div>\r\n",
            "\r\n",
            "\r\n",
            "\r\n",
            "\r\n",
            "  </main>\r\n",
            "</body>\r\n",
            "\r\n",
            "</html>\r\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Once you have obtained the HTML content of a webpage as text, you can extract information from it using various techniques. Here are a couple of common methods:\n",
        "\n",
        "1. **Using String Methods and Regular Expressions**:\n",
        "   - You can use string manipulation methods such as `find()`, `split()`, and `replace()` to locate specific elements or patterns within the HTML content.\n",
        "   - Regular expressions (`re` module) can be employed to search for complex patterns in the HTML content and extract desired information.\n",
        "\n",
        "2. **Using an HTML Parser**:\n",
        "   - Libraries like BeautifulSoup provide powerful tools for parsing HTML content in a structured way.\n",
        "   - BeautifulSoup allows you to navigate and search through the HTML document using methods like `find()`, `find_all()`, and CSS selectors, making it easier to extract specific elements or data.\n",
        "\n",
        "String methods and regular expressions are suitable for simple extraction tasks or when dealing with well-structured HTML content. On the other hand, using an HTML parser like BeautifulSoup is more robust and recommended for complex HTML structures or when you need to handle malformed HTML."
      ],
      "metadata": {
        "id": "uMp9q2ctSnp1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# HTML"
      ],
      "metadata": {
        "id": "NzVL3MPDRAmH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "1. **find()**:  \n",
        "   This method is used to find the index of the first occurrence of a substring within a string. In the example, `html_content.find('<body>')` returns the index of the start of the `<body>` tag in the HTML content.\n",
        "\n",
        "2. **len()**:  \n",
        "   This built-in Python function returns the length of an object. In this context, `len('<body>')` returns the length of the `<body>` tag, which is the number of characters in the string `<body>`.\n",
        "\n",
        "3. **+**:  \n",
        "   This operator is used for concatenating strings in Python. In the example, `html_content.find('<body>') + len('<body>')` calculates the end index of the `<body>` tag.\n",
        "\n",
        "4. **replace()**:  \n",
        "   This method is used to replace occurrences of a specified substring within a string with another substring. In the example, `body_content.replace('<h1>', '')` removes all occurrences of the `<h1>` tags from the body content.\n",
        "\n",
        "5. **strip()**:  \n",
        "   This method is used to remove leading and trailing whitespace characters from a string. In the example, `text_content.strip()` removes any leading or trailing whitespace from the extracted text content.\n",
        "\n",
        "These methods are used together to extract text content from HTML using string manipulation techniques. However, this approach is not robust for handling all cases of HTML content, especially those with complex structures. Using a dedicated HTML parsing library like BeautifulSoup is recommended for more reliable and flexible HTML parsing."
      ],
      "metadata": {
        "id": "4Qj2SfQyQi8N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "html_content = \"\"\"\n",
        "<html>\n",
        "<head>\n",
        "<title>Example Page</title>\n",
        "</head>\n",
        "<body>\n",
        "<h1>Welcome to Example Page</h1>\n",
        "<p>This is a paragraph.</p>\n",
        "<p>This is another paragraph.</p>\n",
        "</body>\n",
        "</html>\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "a3iCzcpnQHAr"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Find the position of the first occurrence of '<body>' tag\n",
        "start_index = html_content.find('<body>') + len('<body>')\n",
        "start_index"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zQWoH_6jLAUS",
        "outputId": "2ee273a7-380f-47cd-b884-169e3ea49126"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Find the position of the last occurrence of '</body>' tag\n",
        "end_index = html_content.find('</body>')\n",
        "end_index"
      ],
      "metadata": {
        "id": "AbDVJtqPlgQE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c6b3ff1-f58d-4543-a259-c8369b7af3f5"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5857"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove any remaining HTML tags using string replace\n",
        "text_content = body_content.replace('<h1>', '').replace('</h1>', '').replace('<p>', '').replace('</p>', '')\n",
        "# Print the extracted text content\n",
        "print(text_content.strip())"
      ],
      "metadata": {
        "id": "bHkDASFTlgMW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "55d88a90-7a46-49f1-8662-da7ced3e9929"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Welcome to Example Page\n",
            "This is a paragraph.\n",
            "This is another paragraph.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract the content between <body> and </body>\n",
        "body_content = html_content[start_index:end_index]\n",
        "body_content"
      ],
      "metadata": {
        "id": "QxAMp-aHlgGi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 154
        },
        "outputId": "8c5991b2-e62e-4328-c6ca-08e48a276a47"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'!DOCTYPE html>\\r\\n<html lang=\"en\">\\r\\n\\r\\n<head>\\r\\n  <title>Kaggle: Your Machine Learning and Data Science Community</title>\\r\\n  <meta charset=\"utf-8\" />\\r\\n    <meta name=\"robots\" content=\"index, follow\" />\\r\\n  <meta name=\"description\" content=\"Kaggle is the world&#x2019;s largest data science community with powerful tools and resources to help you achieve your data science goals.\" />\\r\\n  <meta name=\"turbolinks-cache-control\" content=\"no-cache\" />\\r\\n    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0, maximum-scale=5.0, minimum-scale=1.0\">\\r\\n  <meta name=\"theme-color\" content=\"#008ABC\" />\\r\\n  <script nonce=\"FDBOrchT596&#x2B;PBjKY5dn8g==\" type=\"text/javascript\">\\r\\n    window[\"pageRequestStartTime\"] = 1712488695964;\\r\\n    window[\"pageRequestEndTime\"] = 1712488695970;\\r\\n    window[\"initialPageLoadStartTime\"] = new Date().getTime();\\r\\n  </script>\\r\\n  <script nonce=\"FDBOrchT596&#x2B;PBjKY5dn8g==\" id=\"gsi-client\" src=\"https://accounts.google.com/gsi/client\" async defer></script>\\r\\n  <script nonce=\"FDBOrchT596&#x2B;PBjKY5dn8g==\">window.KAGGLE_JUPYTERLAB_PATH = \"/static/assets/jupyterlab/jupyterlab-index-0497beb6ae1b7d43c42d.html\";</script>\\r\\n  <link rel=\"preconnect\" href=\"https://www.google-analytics.com\" crossorigin=\"anonymous\" /><link rel=\"preconnect\" href=\"https://stats.g.doubleclick.net\" /><link rel=\"preconnect\" href=\"https://storage.googleapis.com\" /><link rel=\"preconnect\" href=\"https://apis.google.com\" />\\r\\n  <link href=\"/static/images/favicon.ico\" rel=\"shortcut icon\" type=\"image/x-icon\" />\\r\\n  <link rel=\"manifest\" href=\"/static/json/manifest.json\" crossorigin=\"use-credentials\">\\r\\n\\r\\n\\r\\n  <link rel=\"preconnect\" href=\"https://fonts.gstatic.com\" crossorigin />\\r\\n\\r\\n  <link href=\"https://fonts.googleapis.com/css?family=Inter:400,400i,500,500i,600,600i,700,700i&display=swap\"\\r\\n    rel=\"preload\" as=\"style\" />\\r\\n  <link href=\"https://fonts.googleapis.com/css2?family=Google+Symbols:FILL@0..1&display=block\"\\r\\n    rel=\"preload\" as=\"style\" />\\r\\n  <link href=\"https://fonts.googleapis.com/css?family=Inter:400,400i,500,500i,600,600i,700,700i&display=swap\"\\r\\n    rel=\"stylesheet\" media=\"print\" id=\"async-google-font-1\" />\\r\\n  <link href=\"https://fonts.googleapis.com/css2?family=Google+Symbols:FILL@0..1&display=block\"\\r\\n    rel=\"stylesheet\" media=\"print\" id=\"async-google-font-2\" />\\r\\n  <script nonce=\"FDBOrchT596&#x2B;PBjKY5dn8g==\" type=\"text/javascript\">\\r\\n    const styleSheetIds = [\"async-google-font-1\", \"async-google-font-2\"];\\r\\n    styleSheetIds.forEach(function (id) {\\r\\n      document.getElementById(id).addEventListener(\"load\", function() {\\r\\n        this.media = \"all\";\\r\\n      });\\r\\n    });\\r\\n  </script>\\r\\n\\r\\n  <script nonce=\"FDBOrchT596&#x2B;PBjKY5dn8g==\" src=\"https://www.google.com/recaptcha/enterprise.js?render=6LcW02cpAAAAAJlaJemsQQEwAiTEYB4aR6FYE_rD&waf=session\" async defer></script>\\r\\n   <style>.grecaptcha-badge { visibility: hidden; }</style>\\r\\n\\r\\n    <link rel=\"stylesheet\" type=\"text/css\" href=\"/static/assets/vendor.css?v=dne\" />\\r\\n    <link rel=\"stylesheet\" type=\"text/css\" href=\"/static/assets/app.css?v=d42a14acad2e5a1bfac8\" />\\r\\n\\r\\n  \\r\\n    \\r\\n \\r\\n      <script nonce=\"FDBOrchT596&#x2B;PBjKY5dn8g==\">\\r\\n        try{(function(a,s,y,n,c,h,i,d,e){d=s.createElement(\"style\");\\r\\n        d.appendChild(s.createTextNode(\"\"));s.head.appendChild(d);d=d.sheet;\\r\\n        y=y.map(x => d.insertRule(x + \"{ opacity: 0 !important }\"));\\r\\n        h.start=1*new Date;h.end=i=function(){y.forEach(x => x<d.cssRules.length ? d.deleteRule(x) : {})};\\r\\n        (a[n]=a[n]||[]).hide=h;setTimeout(function(){i();h.end=null},c);h.timeout=c;\\r\\n        })(window,document,[\\'.site-header-react__nav\\'],\\'dataLayer\\',2000,{\\'GTM-52LNT9S\\':true});}catch(ex){}\\r\\n    </script>\\r\\n    <script nonce=\"FDBOrchT596&#x2B;PBjKY5dn8g==\">\\r\\n        window.dataLayer = window.dataLayer || [];\\r\\n        function gtag() { dataLayer.push(arguments); }\\r\\n        gtag(\\'js\\', new Date());\\r\\n        gtag(\\'config\\', \\'G-T7QHS60L4Q\\', {\\r\\n            \\'optimize_id\\': \\'GTM-52LNT9S\\',\\r\\n            \\'displayFeaturesTask\\': null,\\r\\n            \\'send_page_view\\': false,\\r\\n            \\'content_group1\\': \\'Home\\'\\r\\n        });\\r\\n    </script>\\r\\n    <script nonce=\"FDBOrchT596&#x2B;PBjKY5dn8g==\" async src=\"https://www.googletagmanager.com/gtag/js?id=G-T7QHS60L4Q\"></script>\\r\\n\\r\\n  \\r\\n    \\r\\n    <meta property=\"og:title\" content=\"Kaggle: Your Machine Learning and Data Science Community\" />\\r\\n    <meta property=\"og:description\" content=\"Kaggle is the world&#x2019;s largest data science community with powerful tools and resources to help you achieve your data science goals.\" />\\r\\n    <meta property=\"og:url\" content=\"https://www.kaggle.com/\" />\\r\\n    <meta property=\"og:type\" content=\"website\" />\\r\\n\\r\\n\\r\\n  <meta name=\"twitter:site\" content=\"@Kaggle\" /> \\r\\n  \\r\\n    \\r\\n\\r\\n  \\r\\n    \\r\\n\\r\\n  \\r\\n    \\r\\n\\r\\n\\r\\n    <script nonce=\"FDBOrchT596&#x2B;PBjKY5dn8g==\">window[\\'useKaggleAnalytics\\'] = true;</script>\\r\\n\\r\\n  <script id=\"gapi-target\" nonce=\"FDBOrchT596&#x2B;PBjKY5dn8g==\" src=\"https://apis.google.com/js/api.js\" defer\\r\\n    async></script>\\r\\n  <script nonce=\"FDBOrchT596+PBjKY5dn8g==\" src=\"/static/assets/runtime.js?v=67a0b6ddda2db212e5bb\" data-turbolinks-track=\"reload\"></script>\\r\\n  <script nonce=\"FDBOrchT596+PBjKY5dn8g==\" src=\"/static/assets/vendor.js?v=2edca12929552d93c5db\" data-turbolinks-track=\"reload\"></script>\\r\\n  <script nonce=\"FDBOrchT596+PBjKY5dn8g==\" src=\"/static/assets/app.js?v=1d2f39c032909e684cde\" data-turbolinks-track=\"reload\"></script>\\r\\n    <script nonce=\"FDBOrchT596&#x2B;PBjKY5dn8g==\" type=\"text/javascript\">\\r\\n      window.kaggleStackdriverConfig = {\\r\\n        key: \\'AIzaSyA4eNqUdRRskJsCZWVz-qL655Xa5JEMreE\\',\\r\\n        projectId: \\'kaggle-161607\\',\\r\\n        service: \\'web-fe\\',\\r\\n        version: \\'ci\\',\\r\\n        userId: \\'0\\'\\r\\n      }\\r\\n    </script>\\r\\n</head>\\r\\n\\r\\n<body data-turbolinks=\"false\">\\r\\n  <main>\\r\\n    \\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n<div id=\"site-container\"></div>\\r\\n\\r\\n<div id=\"site-body\" class=\"hide\">\\r\\n    \\r\\n\\r\\n</div>\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n  </main>\\r\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Extract Text From HTML With String Methods"
      ],
      "metadata": {
        "id": "8AfIcGRjTL-8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# HTML content\n",
        "html_content = \"\"\"\n",
        "<html>\n",
        "<head>\n",
        "<title>Example Page</title>\n",
        "</head>\n",
        "<body>\n",
        "<h1>Welcome to Example Page</h1>\n",
        "<p>This is a paragraph.</p>\n",
        "<p>This is another paragraph.</p>\n",
        "</body>\n",
        "</html>\n",
        "\"\"\"\n",
        "\n",
        "# Find the start and end index of the body content\n",
        "start_index = html_content.find('<body>') + len('<body>')\n",
        "end_index = html_content.find('</body>')\n",
        "\n",
        "# Extract the content between <body> and </body>\n",
        "body_content = html_content[start_index:end_index]\n",
        "\n",
        "# Remove HTML tags using string manipulation\n",
        "text_content = \"\"\n",
        "inside_tag = False\n",
        "for char in body_content:\n",
        "    if char == '<':\n",
        "        inside_tag = True\n",
        "    elif char == '>':\n",
        "        inside_tag = False\n",
        "    elif not inside_tag:\n",
        "        text_content += char\n",
        "\n",
        "# Print the extracted text content\n",
        "print(text_content.strip())\n"
      ],
      "metadata": {
        "id": "lowPDtT2lgC4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "88ea28ff-5669-4dce-d76c-a4010edd9e35"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Welcome to Example Page\n",
            "This is a paragraph.\n",
            "This is another paragraph.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "title_index = html.find(\"<title>\")\n",
        "title_index"
      ],
      "metadata": {
        "id": "sPYuIK9glf-_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a532a4a5-7ceb-485e-b7d7-d8e07fd8f44c"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "51"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "url = \"https://www.kaggle.com/\"\n",
        "\n",
        "# Send a request to the webpage and get the response\n",
        "response = urlopen(url)\n",
        "\n",
        "# Read the HTML content as bytes and decode it to a string using UTF-8 encoding\n",
        "html = response.read().decode(\"utf-8\")\n",
        "\n",
        "# Find the start and end index of the title tag\n",
        "start_index = html.find(\"<title>\") + len(\"<title>\")\n",
        "end_index = html.find(\"</title>\")\n",
        "\n",
        "# Extract the content between the title tags\n",
        "title = html[start_index:end_index]\n",
        "\n",
        "# Print the extracted title\n",
        "print(title)"
      ],
      "metadata": {
        "id": "jNr8LPwplf3R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "59f301ac-3a41-46d4-95ff-621c85398871"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Kaggle: Your Machine Learning and Data Science Community\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Regular Expressions"
      ],
      "metadata": {
        "id": "NQM6R5O8USNB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Regular expressions—or regexes for short—are patterns that you can use to search for text within a string. Python supports regular expressions through the standard library’s re module."
      ],
      "metadata": {
        "id": "YPHG6TTPUVPI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Regular expressions, often abbreviated as regex, are sequences of characters that define a search pattern. They are widely used in programming for pattern matching and string manipulation tasks. Here's a brief overview of working with regular expressions:\n",
        "\n",
        "1. **Pattern Creation**: Regular expressions are used to define patterns that you want to search for within a string. These patterns can include literals, metacharacters, and quantifiers.\n",
        "\n",
        "2. **Metacharacters**: Metacharacters are special characters in regex that have a specific meaning. Some common metacharacters include:\n",
        "   - `.` : Matches any single character except newline.\n",
        "   - `^` : Anchors the match to the start of the string.\n",
        "   - `$` : Anchors the match to the end of the string.\n",
        "   - `\\d` : Matches any digit character (equivalent to `[0-9]`).\n",
        "   - `\\w` : Matches any alphanumeric character (equivalent to `[a-zA-Z0-9_]`).\n",
        "   - `\\s` : Matches any whitespace character.\n",
        "   - `[...]` : Matches any single character within the brackets.\n",
        "   - `|` : Acts as an OR operator.\n",
        "\n",
        "3. **Quantifiers**: Quantifiers specify how many times a character or group of characters can occur in the pattern. Some common quantifiers include:\n",
        "   - `*` : Matches zero or more occurrences of the preceding character.\n",
        "   - `+` : Matches one or more occurrences of the preceding character.\n",
        "   - `?` : Matches zero or one occurrence of the preceding character.\n",
        "   - `{n}` : Matches exactly n occurrences of the preceding character.\n",
        "   - `{n,}` : Matches at least n occurrences of the preceding character.\n",
        "   - `{n,m}` : Matches between n and m occurrences of the preceding character.\n",
        "\n",
        "4. **Matching**: Once you have defined a regex pattern, you can use it to search for matches within a string. This is typically done using functions like `re.search()` or `re.findall()` in Python's `re` module.\n",
        "\n",
        "5. **Replacement**: Regular expressions can also be used for string replacement. You can use functions like `re.sub()` to replace matches of a pattern with a specified replacement string.\n",
        "\n",
        "Here's a simple example of using regular expressions in Python:\n",
        "\n",
        "```python\n",
        "import re\n",
        "\n",
        "# Define a regex pattern\n",
        "pattern = r'\\b\\d{3}-\\d{2}-\\d{4}\\b'  # Matches US social security numbers\n",
        "\n",
        "# Define a string to search\n",
        "text = \"John's SSN is 123-45-6789 and Mary's is 987-65-4321.\"\n",
        "\n",
        "# Search for matches of the pattern in the string\n",
        "matches = re.findall(pattern, text)\n",
        "\n",
        "# Print the matches\n",
        "print(matches)\n",
        "```\n",
        "\n",
        "he first argument of re.findall() is the regular expression that you want to match, and the second argument is the string to test."
      ],
      "metadata": {
        "id": "L-joDrFRUfaQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "re.findall(\"ab*c\", \"abcd\")"
      ],
      "metadata": {
        "id": "SADGP5q1lfz7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "36f5da9c-58a8-41dc-b6c2-bb2f5be1a62b"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['abc']"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "re.findall(\"ab*c\", \"acc\")"
      ],
      "metadata": {
        "id": "rqlDh0xnlfww",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "413b248a-8f6b-4ab7-c664-e7a5c46fa4fd"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['ac']"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "re.findall(\"ab*c\", \"abcac\")"
      ],
      "metadata": {
        "id": "x-SBE8lFlfs2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "17115d44-feec-454f-91e1-62b48b5e10e5"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['abc', 'ac']"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "re.findall(\"ab*c\", \"abdc\")"
      ],
      "metadata": {
        "id": "rX_nahpJlfmJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "12fc93e2-3f4e-4361-ee90-14f455730a91"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Extract Text From HTML With Regular Expressions"
      ],
      "metadata": {
        "id": "z0DiGgadVVwf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The regex pattern r'<.*?>(.*?)</.*?>' is used to match HTML tags and their content. The .*? is a non-greedy quantifier that matches any character (except newline) as few times as possible.\n",
        "re.findall() is used to find all matches of the pattern in the HTML content.\n",
        "The matched text is concatenated to form the extracted content."
      ],
      "metadata": {
        "id": "btkE4WdQVieZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# HTML content\n",
        "html_content = \"\"\"\n",
        "<html>\n",
        "<head>\n",
        "<title>Example Page</title>\n",
        "</head>\n",
        "<body>\n",
        "<h1>Welcome to Example Page</h1>\n",
        "<p>This is a paragraph.</p>\n",
        "<p>This is another paragraph.</p>\n",
        "</body>\n",
        "</html>\n",
        "\"\"\"\n",
        "\n",
        "# Define the regex pattern to match HTML tags and their content\n",
        "pattern = r'<.*?>(.*?)</.*?>'\n",
        "\n",
        "# Find all matches of the pattern in the HTML content\n",
        "matches = re.findall(pattern, html_content, re.DOTALL)\n",
        "\n",
        "# Concatenate the matched text to form the extracted content\n",
        "text_content = ' '.join(matches)\n",
        "\n",
        "# Print the extracted text content\n",
        "print(text_content.strip())\n"
      ],
      "metadata": {
        "id": "tfvyodjFlfi8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "915e5ae3-d682-4ad9-f6e1-1740c7fab31a"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<head>\n",
            "<title>Example Page \n",
            "<body>\n",
            "<h1>Welcome to Example Page This is a paragraph. This is another paragraph.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Beautiful Soup\n"
      ],
      "metadata": {
        "id": "vvPMKL8gVqbX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Beautiful Soup is a Python library for parsing HTML and XML documents. It provides tools for navigating the parse tree and searching for elements, making it easier to extract and manipulate data from web pages. Here's an example of how you can use BeautifulSoup to extract information from a webpage\n"
      ],
      "metadata": {
        "id": "DryYgQM1V2J1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# URL of the webpage to scrape\n",
        "url = \"https://www.example.com\"  # Replace with the URL of the webpage\n",
        "\n",
        "# Send a GET request to the webpage\n",
        "response = requests.get(url)\n",
        "\n",
        "# Parse the HTML content of the webpage\n",
        "soup = BeautifulSoup(response.content, 'html.parser')\n",
        "\n",
        "# Find all <img> tags on the page\n",
        "img_tags = soup.find_all(\"img\")\n",
        "\n",
        "# Print the src attribute of each <img> tag\n",
        "for img_tag in img_tags:\n",
        "    src = img_tag.get(\"src\")\n",
        "    print(src)"
      ],
      "metadata": {
        "id": "CxvVZfBTXRCo"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "url = \"http://olympus.realpython.org/profiles/dionysus\"\n",
        "page = urlopen(url)\n",
        "html = page.read().decode(\"utf-8\")\n",
        "soup = BeautifulSoup(html, \"html.parser\")\n",
        "print(soup.get_text())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z_aJmu22XLAd",
        "outputId": "f310832b-0d79-4c08-fb00-be7166f7acbd"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Profile: Dionysus\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Name: Dionysus\n",
            "\n",
            "Hometown: Mount Olympus\n",
            "\n",
            "Favorite animal: Leopard \n",
            "\n",
            "Favorite Color: Wine\n",
            "\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We use the official Medium API endpoint (https://medium.com/_/api/home-feed) to fetch recent articles from the Medium homepage.\n",
        "\n",
        "We specify parameters for the API request, including the limit of articles to retrieve and filtering by the latest articles.\n",
        "\n",
        "We send a GET request to the Medium API endpoint using requests.get() and pass the parameters.\n",
        "\n",
        "If the request is successful (status code 200), we parse the JSON response and extract the article information, including titles and URLs.\n",
        "\n",
        "Finally, we print the titles and links of the recent articles.\n"
      ],
      "metadata": {
        "id": "52A8bbKVWnjm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "soup.find_all(\"img\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3sw1GxSeXAlq",
        "outputId": "74d886f1-f032-4d9f-9331-ca57012b6de7"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<img src=\"/static/dionysus.jpg\"/>, <img src=\"/static/grapes.png\"/>]"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# URL of the Medium API endpoint for fetching recent articles\n",
        "api_url = \"https://medium.com/_/api/home-feed\"\n",
        "\n",
        "# Parameters for the API request\n",
        "params = {\n",
        "    \"limit\": 10,  # Number of articles to retrieve\n",
        "    \"filter\": \"latest\",  # Filter by latest articles\n",
        "}\n",
        "\n",
        "# Send a GET request to the Medium API endpoint\n",
        "response = requests.get(api_url, params=params)\n",
        "\n",
        "# Check if the request was successful (status code 200)\n",
        "if response.status_code == 200:\n",
        "    # Parse the JSON response\n",
        "    data = response.json()\n",
        "\n",
        "    # Extract article information from the response\n",
        "    articles = data[\"payload\"][\"references\"][\"Post\"]\n",
        "\n",
        "    # Print the titles and links of the recent articles\n",
        "    for article_id, article_info in articles.items():\n",
        "        title = article_info[\"title\"]\n",
        "        url = f\"https://medium.com/p/{article_info['uniqueSlug']}\"\n",
        "        print(f\"Title: {title}\")\n",
        "        print(f\"URL: {url}\")\n",
        "        print()\n",
        "else:\n",
        "    print(\"Failed to fetch articles. Please try again later.\")"
      ],
      "metadata": {
        "id": "1N8Pm4gKlfga",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "74d988a3-71a3-4204-b0b0-79b1ed8d72f1"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Failed to fetch articles. Please try again later.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Interact With Websites in Real Time"
      ],
      "metadata": {
        "id": "xRuKtO_RXmqo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "PRUZbwkwlfc2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8fdb20f6-18a7-4389-aa08-69ddce780925"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DfUop_wrlfZ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FOWIqRTolfV7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vsmRe_gnlfRx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}